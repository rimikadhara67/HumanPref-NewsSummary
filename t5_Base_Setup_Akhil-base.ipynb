{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["T5-base code"],"metadata":{"id":"fVy-G3SLoxB_"}},{"cell_type":"code","source":["# --------------------------------------------\n","# 1. Install Required Libraries\n","# --------------------------------------------\n","!pip install -q transformers datasets evaluate rouge-score accelerate nltk\n","\n","# --------------------------------------------\n","# 2. Import Libraries\n","# --------------------------------------------\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    T5Tokenizer,\n","    T5ForConditionalGeneration,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n","    DataCollatorForSeq2Seq\n",")\n","import evaluate\n","import nltk\n","nltk.download(\"punkt\")\n","from tqdm.auto import tqdm\n","\n","# --------------------------------------------\n","# 3. Setup Device\n","# --------------------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# --------------------------------------------\n","# 4. Load Dataset\n","# --------------------------------------------\n","dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n","dataset[\"train\"] = dataset[\"train\"].select(range(2000))\n","dataset[\"validation\"] = dataset[\"validation\"].select(range(500))\n","dataset[\"test\"] = dataset[\"test\"].select(range(200))\n","print(\"Loaded and trimmed dataset.\")\n","\n","# --------------------------------------------\n","# 5. Tokenizer and Preprocessing\n","# --------------------------------------------\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", legacy=False)  # Disable legacy mode\n","\n","max_input_len = 512\n","max_target_len = 128\n","\n","def preprocess(example):\n","    inputs = [\"summarize: \" + article for article in example[\"article\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_len, truncation=True, padding=\"max_length\")\n","    labels = tokenizer(\n","        text_target=example[\"highlights\"],  # New recommended way\n","        max_length=max_target_len,\n","        truncation=True,\n","        padding=\"max_length\"\n","    )\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=dataset[\"train\"].column_names)\n","\n","# --------------------------------------------\n","# 6. Load Model\n","# --------------------------------------------\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n","\n","# --------------------------------------------\n","# 7. Evaluation Metrics\n","# --------------------------------------------\n","rouge = evaluate.load(\"rouge\")\n","meteor = evaluate.load(\"meteor\")\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    decoded_labels = [[label] for label in decoded_labels]\n","\n","    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","\n","    return {\n","        \"rouge1\": round(rouge_result[\"rouge1\"], 4),\n","        \"rouge2\": round(rouge_result[\"rouge2\"], 4),\n","        \"rougeL\": round(rouge_result[\"rougeL\"], 4),\n","        \"meteor\": round(meteor_result[\"meteor\"], 4)\n","    }\n","\n","# --------------------------------------------\n","# 8. Training Args (UPDATED)\n","# --------------------------------------------\n","args = Seq2SeqTrainingArguments(\n","    output_dir=\"./t5_cnn_baseline\",\n","    eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n","    learning_rate=3e-4,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=5,\n","    save_total_limit=2,\n","    predict_with_generate=True,\n","    fp16=torch.cuda.is_available(),\n","    logging_steps=50,\n","    logging_dir=\"./logs\",\n","    report_to=\"none\"  # Disable wandb reporting\n",")\n","\n","# --------------------------------------------\n","# 9. Trainer\n","# --------------------------------------------\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n","    compute_metrics=compute_metrics\n",")\n","\n","# --------------------------------------------\n","# 10. Train & Save\n","# --------------------------------------------\n","print(\"\\nTraining model...\")\n","trainer.train()\n","\n","print(\"\\nSaving model...\")\n","trainer.save_model(\"t5_cnn_baseline_final\")\n","tokenizer.save_pretrained(\"t5_cnn_baseline_final\")\n","\n","# --------------------------------------------\n","# 11. Final Evaluation\n","# --------------------------------------------\n","print(\"\\nEvaluating on test set...\")\n","test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"], metric_key_prefix=\"test\")\n","print(\"\\nTest Results:\")\n","for key, value in test_results.items():\n","    if isinstance(value, float):\n","        print(f\"{key}: {value:.4f}\")\n","\n","# --------------------------------------------\n","# 12. Generate Sample Summaries\n","# --------------------------------------------\n","def generate_summary(text):\n","    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", truncation=True, max_length=max_input_len).to(device)\n","    outputs = model.generate(**inputs, max_length=max_target_len, num_beams=4, early_stopping=True)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(\"\\nSample Summaries:\")\n","for i in range(3):\n","    sample = dataset[\"test\"][i]\n","    print(f\"\\nArticle {i+1} (excerpt):\\n{sample['article'][:200]}...\")\n","    print(f\"\\nReference Summary:\\n{sample['highlights']}\")\n","    print(f\"\\nGenerated Summary:\\n{generate_summary(sample['article'])}\")\n","    print(\"\\n\" + \"-\"*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5ajfcQNWvfwx","executionInfo":{"status":"ok","timestamp":1745197778240,"user_tz":300,"elapsed":1639318,"user":{"displayName":"Akhil Mavallapalli","userId":"02508402536572482827"}},"outputId":"55b53cde-d6b6-4aca-d25a-450cc17944e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Loaded and trimmed dataset.\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","<ipython-input-8-9711e80645f8>:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training model...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2500/2500 26:12, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.899100</td>\n","      <td>0.759190</td>\n","      <td>0.243800</td>\n","      <td>0.094300</td>\n","      <td>0.198000</td>\n","      <td>0.147300</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.655200</td>\n","      <td>0.801670</td>\n","      <td>0.241100</td>\n","      <td>0.089600</td>\n","      <td>0.195100</td>\n","      <td>0.145200</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.501800</td>\n","      <td>0.834631</td>\n","      <td>0.250700</td>\n","      <td>0.093700</td>\n","      <td>0.203600</td>\n","      <td>0.151700</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.414400</td>\n","      <td>0.868797</td>\n","      <td>0.244200</td>\n","      <td>0.093300</td>\n","      <td>0.199200</td>\n","      <td>0.149400</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.415200</td>\n","      <td>0.875853</td>\n","      <td>0.244300</td>\n","      <td>0.093400</td>\n","      <td>0.199500</td>\n","      <td>0.149200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Saving model...\n","\n","Evaluating on test set...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [50/50 00:37]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Test Results:\n","test_loss: 0.9011\n","test_rouge1: 0.2468\n","test_rouge2: 0.0890\n","test_rougeL: 0.1998\n","test_meteor: 0.1495\n","test_runtime: 41.1904\n","test_samples_per_second: 4.8560\n","test_steps_per_second: 1.2140\n","epoch: 5.0000\n","\n","Sample Summaries:\n","\n","Article 1 (excerpt):\n","(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territor...\n","\n","Reference Summary:\n","Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n","Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n","\n","Generated Summary:\n","Palestinian Authority becomes 123rd member of International Criminal Court . Court gives jurisdiction over alleged crimes committed in Palestinian territories . Palestinians may be subject to counter-charges as well .\n","\n","--------------------------------------------------------------------------------\n","\n","Article 2 (excerpt):\n","(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided me...\n","\n","Reference Summary:\n","Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n","\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n","\n","Generated Summary:\n","Bully breed mix named Theia survived after being hit by car, buried in field . Dog apparently whacked on head with hammer four days after her death . Dog taken in by Washington vet Sara Mellado . Donors have raised $10,000 for dog's care .\n","\n","--------------------------------------------------------------------------------\n","\n","Article 3 (excerpt):\n","(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of Sta...\n","\n","Reference Summary:\n","Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n","He once participated in a takeover of the Iranian Consulate in San Francisco .\n","The Iranian foreign minister tweets in English .\n","\n","Generated Summary:\n","Mohammad Javad Zarif tweeted \"Happy Rosh Hashanah\" in September 2013 . He was nominated to be Iran's foreign minister by Ahmadinejad's successor . Zarif left Iran in 1977 and received his Nobel Peace Prize in 1979 . He has helped secure a breakthrough in nuclear talks that could end sanctions .\n","\n","--------------------------------------------------------------------------------\n"]}]}]}