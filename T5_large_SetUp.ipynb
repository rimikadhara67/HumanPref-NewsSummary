{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPlUupKoJH8GhX8nis6jFcW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["T5-Large"],"metadata":{"id":"7n5FXYskfCIy"}},{"cell_type":"code","source":["#!/usr/bin/env python3\n","# Complete T5-Large Summarization Pipeline with Fixed Metric Loading\n","import torch\n","import evaluate\n","import nltk\n","import numpy as np\n","import os\n","import shutil\n","from datasets import load_dataset\n","from transformers import (\n","    T5Tokenizer,\n","    T5ForConditionalGeneration,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n","    DataCollatorForSeq2Seq\n",")\n","\n","# --------------------------------------------\n","# 1. Setup Environment\n","# --------------------------------------------\n","print(\" Setting up environment...\")\n","nltk.download(\"punkt\", quiet=True)\n","\n","# Cleanup potential conflicts\n","for path in [\"rouge\", \"rouge_score\"]:\n","    if os.path.exists(path):\n","        print(f\" Removing conflicting path: {path}\")\n","        shutil.rmtree(path, ignore_errors=True)\n","\n","# --------------------------------------------\n","# 2. Hardware Configuration\n","# --------------------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\" Using device: {device}\")\n","print(f\"BF16 Supported: {torch.cuda.is_bf16_supported()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n","\n","# --------------------------------------------\n","# 3. Load and Prepare Dataset\n","# --------------------------------------------\n","print(\"\\n Loading dataset...\")\n","try:\n","    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n","    dataset = dataset.remove_columns([col for col in dataset[\"train\"].column_names if col not in [\"article\", \"highlights\"]])\n","\n","    # Reduced dataset for quick execution\n","    dataset[\"train\"] = dataset[\"train\"].select(range(1000))\n","    dataset[\"validation\"] = dataset[\"validation\"].select(range(200))\n","    dataset[\"test\"] = dataset[\"test\"].select(range(100))\n","\n","    print(\" Dataset samples:\")\n","    print(f\"Train: {len(dataset['train'])} | Val: {len(dataset['validation'])} | Test: {len(dataset['test'])}\")\n","except Exception as e:\n","    raise RuntimeError(f\"Failed to load dataset: {e}\")\n","\n","# --------------------------------------------\n","# 4. Initialize Tokenizer and Model\n","# --------------------------------------------\n","print(\"\\n Loading model...\")\n","model_name = \"t5-large\"\n","try:\n","    tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n","    model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n","except Exception as e:\n","    raise RuntimeError(f\"Model loading failed: {e}\")\n","\n","# --------------------------------------------\n","# 5. Data Preprocessing\n","# --------------------------------------------\n","max_input_len = 1024\n","max_target_len = 256\n","\n","def preprocess(example):\n","    try:\n","        inputs = [\"summarize: \" + (article if article else \"\") for article in example[\"article\"]]\n","        highlights = [highlight if highlight else \" \" for highlight in example[\"highlights\"]]\n","\n","        model_inputs = tokenizer(\n","            inputs,\n","            max_length=max_input_len,\n","            truncation=True,\n","            padding=\"max_length\"\n","        )\n","        labels = tokenizer(\n","            text_target=highlights,\n","            max_length=max_target_len,\n","            truncation=True,\n","            padding=\"max_length\"\n","        )\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","        return model_inputs\n","    except Exception as e:\n","        print(f\" Preprocessing error: {e}\")\n","        return None\n","\n","print(\"\\n Tokenizing dataset...\")\n","tokenized_dataset = dataset.map(\n","    preprocess,\n","    batched=True,\n","    remove_columns=dataset[\"train\"].column_names,\n","    batch_size=128\n",")\n","\n","# --------------------------------------------\n","# 6. Metrics Setup (Fixed Version)\n","# --------------------------------------------\n","print(\"\\n Setting up metrics...\")\n","try:\n","    # First try loading from evaluate\n","    rouge = evaluate.load(\"rouge\")\n","except:\n","    # Fallback to local installation\n","    print(\" Failed to load ROUGE from evaluate, trying alternative approach...\")\n","    try:\n","        !pip install -q rouge-score\n","        from rouge_score import rouge_scorer\n","        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","\n","        # Create evaluate-compatible wrapper\n","        class RougeWrapper:\n","            def compute(self, predictions, references, **kwargs):\n","                scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n","                count = 0\n","                for pred, ref in zip(predictions, references):\n","                    if isinstance(ref, list):\n","                        ref = ref[0]  # Take first reference if multiple\n","                    score = rouge.score(pred, ref)\n","                    for key in scores:\n","                        scores[key] += score[key].fmeasure\n","                    count += 1\n","                return {k: v/count for k, v in scores.items()}\n","\n","        rouge = RougeWrapper()\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to load ROUGE metric: {e}\")\n","\n","try:\n","    meteor = evaluate.load(\"meteor\")\n","except:\n","    print(\" METEOR not available, using dummy metric\")\n","    meteor = type('', (), {'compute': lambda *args, **kwargs: {\"meteor\": 0}})()\n","\n","def compute_metrics(eval_preds):\n","    try:\n","        preds, labels = eval_preds\n","        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        # Handle single reference vs multiple references\n","        if isinstance(decoded_labels[0], str):\n","            decoded_labels = [[label] for label in decoded_labels]\n","\n","        rouge_result = rouge.compute(\n","            predictions=decoded_preds,\n","            references=decoded_labels,\n","            use_stemmer=True\n","        )\n","        meteor_result = meteor.compute(\n","            predictions=decoded_preds,\n","            references=decoded_labels\n","        )\n","\n","        return {\n","            \"rouge1\": round(rouge_result.get(\"rouge1\", 0), 4),\n","            \"rouge2\": round(rouge_result.get(\"rouge2\", 0), 4),\n","            \"rougeL\": round(rouge_result.get(\"rougeL\", 0), 4),\n","            \"meteor\": round(meteor_result.get(\"meteor\", 0), 4)\n","        }\n","    except Exception as e:\n","        print(f\" Metric computation failed: {e}\")\n","        return {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0, \"meteor\": 0}\n","\n","# --------------------------------------------\n","# 7. Training Configuration\n","# --------------------------------------------\n","print(\"\\n Configuring training...\")\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./t5_summarization\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=4e-4,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,\n","    save_total_limit=2,\n","    predict_with_generate=True,\n","    bf16=torch.cuda.is_bf16_supported(),\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    report_to=\"none\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"rougeL\",\n","    gradient_accumulation_steps=2,\n","    gradient_checkpointing=True\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n","    compute_metrics=compute_metrics\n",")\n","\n","# --------------------------------------------\n","# 8. Execute Training\n","# --------------------------------------------\n","print(\"\\n Starting training...\")\n","try:\n","    train_result = trainer.train()\n","    print(f\"\\n Training completed! Final metrics: {train_result.metrics}\")\n","except Exception as e:\n","    raise RuntimeError(f\"Training failed: {e}\")\n","\n","# --------------------------------------------\n","# 9. Save and Evaluate\n","# --------------------------------------------\n","print(\"\\n Saving model...\")\n","trainer.save_model(\"./t5_summarization_final\")\n","tokenizer.save_pretrained(\"./t5_summarization_final\")\n","\n","print(\"\\n Evaluating on test set...\")\n","test_results = trainer.evaluate(\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    metric_key_prefix=\"test\"\n",")\n","print(\"\\n Test Results:\")\n","for key, value in test_results.items():\n","    if isinstance(value, float):\n","        print(f\"{key}: {value:.4f}\")\n","\n","# --------------------------------------------\n","# 10. Generate Sample Summaries\n","# --------------------------------------------\n","def generate_summary(text, max_length=256):\n","    try:\n","        inputs = tokenizer(\n","            \"summarize: \" + text,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            max_length=max_input_len\n","        ).to(device)\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_length=max_length,\n","                num_beams=4,\n","                early_stopping=True\n","            )\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    except Exception as e:\n","        return f\"[ERROR] Generation failed: {e}\"\n","\n","print(\"\\n Sample Summaries:\")\n","for i in range(3):\n","    sample = dataset[\"test\"][i]\n","    print(f\"\\n Article {i+1} (excerpt):\")\n","    print(sample[\"article\"][:200] + \"...\")\n","    print(f\"\\n Reference Summary:\")\n","    print(sample[\"highlights\"])\n","    print(f\"\\n Generated Summary:\")\n","    print(generate_summary(sample[\"article\"]))\n","    print(\"\\n\" + \"=\"*80)\n","\n","print(\"\\n Pipeline executed successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FJrE7IzyZwyy","executionInfo":{"status":"ok","timestamp":1745207731039,"user_tz":300,"elapsed":339398,"user":{"displayName":"Akhil Mavallapalli","userId":"02508402536572482827"}},"outputId":"8d96314c-2ffe-433b-fe0c-c9c67140bd53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Setting up environment...\n"," Using device: cuda\n","BF16 Supported: True\n","GPU Memory: 42.5GB\n","\n"," Loading dataset...\n"," Dataset samples:\n","Train: 1000 | Val: 200 | Test: 100\n","\n"," Loading model...\n","\n","‚è≥ Tokenizing dataset...\n","\n"," Setting up metrics...\n"," Failed to load ROUGE from evaluate, trying alternative approach...\n"," METEOR not available, using dummy metric\n","\n"," Configuring training...\n","\n"," Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-97916bdab20a>:200: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n","`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 04:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.311600</td>\n","      <td>0.300751</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"stream","name":"stdout","text":[" Metric computation failed: 'RougeWrapper' object has no attribute 'score'\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training completed! Final metrics: {'train_runtime': 276.9959, 'train_samples_per_second': 3.61, 'train_steps_per_second': 0.451, 'total_flos': 4330094592000000.0, 'train_loss': 0.5249381093978882, 'epoch': 1.0}\n","\n"," Saving model...\n","\n"," Evaluating on test set...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25/25 00:34]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Metric computation failed: 'RougeWrapper' object has no attribute 'score'\n","\n"," Test Results:\n","test_loss: 0.3205\n","test_runtime: 37.5028\n","test_samples_per_second: 2.6660\n","test_steps_per_second: 0.6670\n","epoch: 1.0000\n","\n"," Sample Summaries:\n","\n"," Article 1 (excerpt):\n","(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territor...\n","\n"," Reference Summary:\n","Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n","Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n","\n"," Generated Summary:\n","Palestinian Authority officially becomes 123rd member of International Criminal Court . Court has jurisdiction over alleged crimes committed in Palestinian territories . Israel and the United States, neither of which is an ICC member, opposed the move .\n","\n","================================================================================\n","\n"," Article 2 (excerpt):\n","(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided me...\n","\n"," Reference Summary:\n","Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n","\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n","\n"," Generated Summary:\n","The dog was hit by a car, apparently whacked with a hammer and buried in a field . She staggered to a nearby farm, dirt-covered and emaciated, where she was found . She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity .\n","\n","================================================================================\n","\n"," Article 3 (excerpt):\n","(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of Sta...\n","\n"," Reference Summary:\n","Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n","He once participated in a takeover of the Iranian Consulate in San Francisco .\n","The Iranian foreign minister tweets in English .\n","\n"," Generated Summary:\n","Mohammad Javad Zarif is the Iranian foreign minister . He has been U.S. Secretary of State John Kerry's opposite number . Zarif has helped bring Iran in from the cold . But there are some facts about him that are less well-known .\n","\n","================================================================================\n","\n"," Pipeline executed successfully!\n"]}]}]}